# backend/app/chatbot/build_vectorstore.py

import os
import shutil
from pymongo import MongoClient
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# ----- Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ -----
MONGO_URL = 'mongodb://172.25.240.1:27017/'
DATABASE_NAME = 'news_database'
COLLECTION_NAME = 'articles'
SAVE_PATH = "faiss_index"

CHUNK_SIZE = 1000
CHUNK_OVERLAP = 100
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

# ----- MongoDB ÏƒÏÎ½Î´ÎµÏƒÎ· -----
def connect_to_mongo():
    client = MongoClient(MONGO_URL)
    db = client[DATABASE_NAME]
    return db[COLLECTION_NAME]

# ----- Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¬ÏÎ¸ÏÏ‰Î½ -----
def load_articles():
    collection = connect_to_mongo()
    articles = list(collection.find())

    if not articles:
        raise ValueError(" Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î¬ÏÎ¸ÏÎ± ÏƒÏ„Î· Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½!")

    print(f" Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(articles)} Î¬ÏÎ¸ÏÎ± Î³Î¹Î± ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±.")
    return articles

# ----- Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± chunks -----
def create_chunks(articles):
    texts = []
    metadatas = []

    for article in articles:
        content = article.get('content', '').strip()
        title = article.get('title', 'Î†Î³Î½Ï‰ÏƒÏ„Î¿Ï‚ Î¤Î¯Ï„Î»Î¿Ï‚')
        link = article.get('link', '')
        published_date = article.get('published_date', '')
        category = article.get('category', 'General')

        if not content:
            continue

        combined_text = f"{title}\n\n{content}"

        for i in range(0, len(combined_text), CHUNK_SIZE - CHUNK_OVERLAP):
            chunk = combined_text[i:i + CHUNK_SIZE]
            if chunk.strip():
                texts.append(chunk)
                metadatas.append({
                    "title": title,
                    "link": link,
                    "published_date": published_date,
                    "category": category
                })

    print(f" Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ {len(texts)} chunks Î³Î¹Î± embeddings.")
    return texts, metadatas

# ----- Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¹ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· FAISS vectorstore -----
def build_vectorstore():
    print(" ÎÎµÎºÎ¹Î½Î¬ Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ Ï„Î¿Ï… FAISS vectorstore...")

    articles = load_articles()
    texts, metadatas = create_chunks(articles)

    embedder = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)

    if os.path.exists(SAVE_PATH):
        shutil.rmtree(SAVE_PATH)
        print("ğŸ§¹ Î”Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ Ï„Î¿ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î¿ FAISS index.")

    vectorstore = FAISS.from_texts(texts, embedder, metadatas=metadatas)
    vectorstore.save_local(SAVE_PATH)

    print(f"âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± FAISS vectorstore Î¼Îµ {len(texts)} chunks!")

# ----- Î•ÎºÎºÎ¯Î½Î·ÏƒÎ· -----
if __name__ == "__main__":
    build_vectorstore()
